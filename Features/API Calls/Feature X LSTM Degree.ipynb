{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"Feature X LSTM.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["Nhq9Mwd3Sd4K"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"x3r6Eochbhcr"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"x3r6Eochbhcr","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nhq9Mwd3Sd4K"},"source":["#Feature Extraction CSVs"],"id":"Nhq9Mwd3Sd4K"},{"cell_type":"code","metadata":{"id":"first-football"},"source":["import networkx as nx\n","import time\n","import argparse\n","import csv\n","from multiprocessing import Pool as ThreadPool\n","from functools import partial\n","import glob"],"id":"first-football","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"romance-mediterranean"},"source":["def obtain_sensitive_apis(file):\n","    print(\"In Obtain_Sensitive_APIs\")\n","    sensitive_apis = []\n","    with open(file, 'r') as f:\n","        for line in f.readlines():\n","            if line.strip() == '':\n","                continue\n","            else:\n","                sensitive_apis.append(line.strip())\n","    print(\"Out Obtain_Sensitive_APIs\")\n","    return sensitive_apis"],"id":"romance-mediterranean","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"portable-grace"},"source":["def callgraph_extraction(file):\n","    CG = nx.read_gexf(file)\n","    return CG"],"id":"portable-grace","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"public-dover"},"source":["def degree_centrality_feature(file, sensitive_apis):\n","    print(\"In Degree\")\n","    sha256 = file.split('/')[-1].split('.')[0]\n","    CG = callgraph_extraction(file)\n","    node_centrality = nx.degree_centrality(CG)\n","    \n","    vector = []\n","    for api in sensitive_apis:\n","        if api in node_centrality.keys():\n","            vector.append(node_centrality[api])\n","        else:\n","            vector.append(0)\n","    print(\"Out Degree\")\n","    return (sha256, vector)"],"id":"public-dover","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"canadian-reservation"},"source":["def katz_centrality_feature(file, sensitive_apis):\n","    print(\"In Katz\")\n","    sha256 = file.split('/')[-1].split('.')[0]\n","    CG = callgraph_extraction(file)\n","    node_centrality = nx.katz_centrality(CG)\n","\n","    vector = []\n","    for api in sensitive_apis:\n","        if api in node_centrality.keys():\n","            vector.append(node_centrality[api])\n","        else:\n","            vector.append(0)\n","    print(\"Out Katz\")\n","    return (sha256, vector)"],"id":"canadian-reservation","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fantastic-projector"},"source":["def closeness_centrality_feature(file, sensitive_apis):\n","    print(\"In Closeness\")\n","    sha256 = file.split('/')[-1].split('.')[0]\n","    CG = callgraph_extraction(file)\n","    node_centrality = nx.closeness_centrality(CG)\n","    \n","    vector = []\n","    for api in sensitive_apis:\n","        if api in node_centrality.keys():\n","            vector.append(node_centrality[api])\n","        else:\n","            vector.append(0)\n","    \n","    print(\"Out Closeness\")\n","    return (sha256, vector)"],"id":"fantastic-projector","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"closing-envelope"},"source":["def harmonic_centrality_feature(file, sensitive_apis):\n","    print(\"In Harmonic\")\n","    sha256 = file.split('/')[-1].split('.')[0]\n","    CG = callgraph_extraction(file)\n","    node_centrality = nx.harmonic_centrality(CG)\n","    \n","    vector = []\n","    for api in sensitive_apis:\n","        if api in node_centrality.keys():\n","            vector.append(node_centrality[api])\n","        else:\n","            vector.append(0)\n","    print(\"Out Harmonic\")\n","    return (sha256, vector)\n"],"id":"closing-envelope","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"confused-chuck"},"source":["def obtain_dataset(dataset_path, centrality_type, sensitive_apis):\n","    Vectors = []\n","    Labels = []\n","    \n","    print(\"In Obtain_Dataset\")\n","    if dataset_path[-1] == '/':\n","        apps_b = glob.glob(dataset_path + 'Benign/*.gexf')\n","        apps_m = glob.glob(dataset_path + 'Malign/*.gexf')\n","    else:\n","        apps_b = glob.glob(dataset_path + '/Benign/*.gexf')\n","        apps_m = glob.glob(dataset_path + '/Malign/*.gexf')\n","    print(len(apps_b),len(apps_m))\n","\n","    pool_b = ThreadPool(15)\n","    pool_m = ThreadPool(15)\n","    if centrality_type == 'degree':\n","        vector_b = pool_b.map(partial(degree_centrality_feature, sensitive_apis=sensitive_apis), apps_b)\n","        vector_m = pool_m.map(partial(degree_centrality_feature, sensitive_apis=sensitive_apis), apps_m)\n","    elif centrality_type == 'katz':\n","        vector_b = pool_b.map(partial(katz_centrality_feature, sensitive_apis=sensitive_apis), apps_b)\n","        vector_m = pool_m.map(partial(katz_centrality_feature, sensitive_apis=sensitive_apis), apps_m)\n","    elif centrality_type == 'closeness':\n","        vector_b = pool_b.map(partial(closeness_centrality_feature, sensitive_apis=sensitive_apis), apps_b)\n","        vector_m = pool_m.map(partial(closeness_centrality_feature, sensitive_apis=sensitive_apis), apps_m)\n","    elif centrality_type == 'harmonic':\n","        vector_b = pool_b.map(partial(harmonic_centrality_feature, sensitive_apis=sensitive_apis), apps_b)\n","        vector_m = pool_m.map(partial(harmonic_centrality_feature, sensitive_apis=sensitive_apis), apps_m)\n","    else:\n","        print('Error Centrality Type!')\n","\n","    Vectors.extend(vector_b)\n","    Labels.extend([0 for i in range(len(vector_b))])\n","\n","    Vectors.extend(vector_m)\n","    Labels.extend([1 for i in range(len(vector_m))])\n","    \n","    print(\"Out Obtain_Dataset\")\n","    return Vectors, Labels"],"id":"confused-chuck","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"italian-november"},"source":["def main():\n","    sensitive_apis_path = '/content/drive/MyDrive/Project BE 2020-2021/Semi Final/sensitive_apis.txt'\n","    sensitive_apis = obtain_sensitive_apis(sensitive_apis_path)\n","\n","    dataset_path = \"/content/drive/MyDrive/Project BE 2020-2021/Semi Final/gefx files/\"\n","    output_path = \"/content/drive/MyDrive/Project BE 2020-2021/Semi Final/gefx files/\"\n","\n","\n","    # cetrality_type = 'degree'\n","    cetrality_type = 'katz'\n","    # cetrality_type = 'closeness'\n","    # cetrality_type = 'harmonic'\n","\n","    Vectors, Labels = obtain_dataset(dataset_path, cetrality_type, sensitive_apis)\n","    feature_csv = [[] for i in range(len(Labels)+1)]\n","    feature_csv[0].append('SHA256')\n","    feature_csv[0].extend(sensitive_apis)\n","    feature_csv[0].append('Label')\n","\n","    for i in range(len(Labels)):\n","        (sha256, vector) = Vectors[i]\n","        feature_csv[i+1].append(sha256)\n","        feature_csv[i+1].extend(vector)\n","        feature_csv[i+1].append(Labels[i])\n","\n","    if output_path[-1] == '/':\n","        csv_path = output_path + cetrality_type + '_features.csv'\n","    else:\n","        csv_path = output_path + '/' + cetrality_type + '_features.csv'\n","\n","    with open(csv_path, 'w', newline='') as f:\n","        csvfile = csv.writer(f)\n","        csvfile.writerows(feature_csv)"],"id":"italian-november","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"human-houston"},"source":["if __name__ == '__main__':\n","    main()"],"id":"human-houston","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lT5AAVuBSijx"},"source":["#LSTM Model Training"],"id":"lT5AAVuBSijx"},{"cell_type":"code","metadata":{"id":"jxcupfRKcUoK"},"source":["from __future__ import print_function\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","np.random.seed(1337)  # for reproducibility\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Embedding\n","from keras.layers import LSTM, SimpleRNN, GRU\n","from keras.datasets import imdb\n","from keras.utils.np_utils import to_categorical\n","from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n","from sklearn import metrics\n","from sklearn.preprocessing import Normalizer\n","import h5py\n","from keras import callbacks\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"],"id":"jxcupfRKcUoK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"drznSpCtUUjQ"},"source":["# cetrality_type = 'degree'\n","# cetrality_type = 'katz'\n","cetrality_type = 'closeness'\n","# cetrality_type = 'harmonic'"],"id":"drznSpCtUUjQ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEIpMdLUTWc6"},"source":["X = pd.read_csv('/content/drive/MyDrive/Project BE 2020-2021/Semi Final/gefx files/' + cetrality_type + '_features.csv')\n","T = pd.read_csv('/content/drive/MyDrive/Project BE 2020-2021/Semi Final/gefx files/' + cetrality_type + '_features.csv')"],"id":"lEIpMdLUTWc6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2o0H4_pfArD"},"source":["X.shape"],"id":"v2o0H4_pfArD","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJtL71xLfEbE"},"source":["T.shape"],"id":"TJtL71xLfEbE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vKni0uAfKMB"},"source":["T.columns"],"id":"0vKni0uAfKMB","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2E6jj4CTWbv"},"source":["Y = X['Label']\n","X = X.drop(labels=['Label', 'SHA256'], axis=1)\n","C = T['Label']\n","T = T.drop(labels=['Label', 'SHA256'], axis=1)"],"id":"n2E6jj4CTWbv","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TiU9DywhTWaa"},"source":["scaler = Normalizer().fit(X)\n","X = scaler.transform(X)\n","# summarize transformed data\n","np.set_printoptions(precision=3)\n","#print(trainX[0:5,:])"],"id":"TiU9DywhTWaa","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVXAkA97TWZK"},"source":["scaler = Normalizer().fit(T)\n","T = scaler.transform(T)\n","# summarize transformed data\n","np.set_printoptions(precision=3)\n","#print(testT[0:5,:])"],"id":"TVXAkA97TWZK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9F2cp37TWXz"},"source":["y_train = np.array(Y)\n","y_test = np.array(C)"],"id":"a9F2cp37TWXz","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vC0W_uxETV_E"},"source":["# reshape input to be [samples, time steps, features]\n","X_train = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n","X_test = np.reshape(T, (T.shape[0], 1, T.shape[1]))"],"id":"vC0W_uxETV_E","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxdMmwE9TV8d"},"source":["batch_size = 32"],"id":"sxdMmwE9TV8d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"umsqVOMxTV6H"},"source":["# 1. define the network\n","model = Sequential()\n","model.add(SimpleRNN(64,input_dim=X.shape[1], return_sequences=True))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(SimpleRNN(64, return_sequences=True))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(SimpleRNN(64, return_sequences=True))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(SimpleRNN(64, return_sequences=True))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(SimpleRNN(64, return_sequences=True))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(SimpleRNN(64, return_sequences=False))  # try using a GRU instead, for fun\n","model.add(Dropout(0.1))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))"],"id":"umsqVOMxTV6H","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dz7yJN-MTV3u"},"source":["# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","checkpointer = callbacks.ModelCheckpoint(filepath=\"logs/5/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n","# csv_logger = CSVLogger('logs/5/training_set_iranalysis.csv',separator=',', append=False)\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=50, validation_data=(X_test, y_test),callbacks=[checkpointer])\n","model.save(\"/content/drive/MyDrive/Project BE 2020-2021/Semi Final/LSTM Models/LSTM_\" + cetrality_type + \"_model.hdf5\")"],"id":"Dz7yJN-MTV3u","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrNEfEu0TV1J"},"source":["model.load_weights(\"/content/drive/MyDrive/Project BE 2020-2021/Semi Final/LSTM Models/LSTM_\" + cetrality_type + \"_model.hdf5\")\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","loss, accuracy = model.evaluate(X_train, y_train)\n","print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"],"id":"DrNEfEu0TV1J","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-y0UgIdTVxP"},"source":["from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)"],"id":"P-y0UgIdTVxP","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMQJTDYJTVuq"},"source":["expected = y_train\n","predicted = model.predict_classes(X_train)"],"id":"tMQJTDYJTVuq","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMCrDhXZTVsT"},"source":["accuracy = accuracy_score(expected, predicted)\n","precision = precision_score(expected, predicted)\n","recall = recall_score(expected, predicted, average=\"binary\")\n","f1 = f1_score(expected, predicted , average=\"binary\")"],"id":"FMCrDhXZTVsT","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWIXuxkHTVp1"},"source":["print(\"Accuracy\")\n","print(\"%.3f\" %accuracy)\n","print(\"precision\")\n","print(\"%.3f\" % precision)\n","print(\"recall\")\n","print(\"%.3f\" %recall)\n","print(\"f-score\")\n","print(\"%.3f\" %f1)"],"id":"vWIXuxkHTVp1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HjUYtaqD_h3"},"source":[""],"id":"-HjUYtaqD_h3","execution_count":null,"outputs":[]}]}